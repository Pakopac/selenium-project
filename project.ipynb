{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d70d02f0-4aff-45f1-858f-ac52c788ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (4.1.0)\n",
      "Requirement already satisfied: pandas in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.3.5)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from selenium->-r requirements.txt (line 1)) (1.26.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from selenium->-r requirements.txt (line 1)) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from selenium->-r requirements.txt (line 1)) (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (1.21.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14; extra == \"secure\" in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from urllib3[secure]~=1.26->selenium->-r requirements.txt (line 1)) (21.0.0)\n",
      "Requirement already satisfied: idna>=2.0.0; extra == \"secure\" in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from urllib3[secure]~=1.26->selenium->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: cryptography>=1.3.4; extra == \"secure\" in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from urllib3[secure]~=1.26->selenium->-r requirements.txt (line 1)) (36.0.0)\n",
      "Requirement already satisfied: certifi; extra == \"secure\" in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from urllib3[secure]~=1.26->selenium->-r requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: async-generator>=1.10 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (1.10)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: outcome in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (21.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: sniffio in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from cryptography>=1.3.4; extra == \"secure\"->urllib3[secure]~=1.26->selenium->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: pycparser in /home/lilian/scrapping-python/env/lib/python3.7/site-packages (from cffi>=1.12->cryptography>=1.3.4; extra == \"secure\"->urllib3[secure]~=1.26->selenium->-r requirements.txt (line 1)) (2.21)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e8aa25db-4890-4773-9bb2-7dc598ca799b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lilian/scrapping-python/env/bin'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Download chromedriver here: https://chromedriver.chromium.org/downloads\n",
    "And add exe file in this folder\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "os.path.dirname(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7011758-c323-4d8c-9f0e-3b41221162c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4d012a8a-c76d-49a3-a041-941f196c0d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for items\n",
    "class Item:\n",
    "    def __init__(self):\n",
    "        self.name = \"\"\n",
    "        self.damage = \"\"\n",
    "        self.tears = \"\"\n",
    "        self.range = \"\"\n",
    "    \n",
    "    # function to check if item with this name already exist\n",
    "    def searchByName(self, name):\n",
    "        if self.name == name:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "45641757-9f7d-4ad7-980e-adf44bd0b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for characters\n",
    "class Character:\n",
    "    def __init__(self):\n",
    "        self.name = \"\"\n",
    "        self.damage = \"\"\n",
    "        self.tears = \"\"\n",
    "        self.range = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4d18f953-f240-4d07-8471-e69788d8e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary array for items\n",
    "array = []\n",
    "\n",
    "# Function to get items stats\n",
    "def getStats(rows, typeStat):\n",
    "    for row in rows:\n",
    "        # Get all names and description of items\n",
    "        name = row.find_elements(By.TAG_NAME, 'td')[0].text\n",
    "        desc = row.find_elements(By.TAG_NAME, 'td')[4].text.lower()\n",
    "        \n",
    "        \"\"\" \n",
    "            Check \"+\" to get only description with statistics (example : \"+1 damage\")\n",
    "            Items without statisic values does not interest us.\n",
    "        \"\"\"\n",
    "        if \"+\" in desc:\n",
    "            # Split all words in description to get only what we want\n",
    "            descArr = desc.split(' ')\n",
    "            \n",
    "            for i in range(len(descArr)):\n",
    "                \"\"\"\n",
    "                    We need to get only number before statistic \n",
    "                    i < len(descArr) - 1 -> to avoid index out of range\n",
    "                    \"+\" in descArr[i]  -> to check values with \"+\"\n",
    "                    descArr[i+1] == typeStat or descArr[i+1] == typeStat + ',' -> to check value before a statistic name\n",
    "                \"\"\"\n",
    "                if i < len(descArr) - 1 and \"+\" in descArr[i] and (descArr[i+1] == typeStat or descArr[i+1] == typeStat + ','):\n",
    "                    # New instance of item with name, damage, tears, range\n",
    "                    item = Item()\n",
    "                    item.name = name\n",
    "                    if(typeStat == \"damage\"):\n",
    "                        item.damage = desc.split(' ')[i]\n",
    "                        array.append(item)\n",
    "                    elif(typeStat == \"tears\"):\n",
    "                        isExist = False\n",
    "                        # If item already exist juste add the statistic\n",
    "                        for existItem in array:\n",
    "                            if(existItem.searchByName(name) == True):\n",
    "                                existItem.tears = desc.split(' ')[i]\n",
    "                                isExist = True\n",
    "                        if isExist == False:\n",
    "                            item.tears = desc.split(' ')[i]\n",
    "                            array.append(item)\n",
    "                    elif(typeStat == \"range\"):\n",
    "                        isExist = False\n",
    "                        for existItem in array:\n",
    "                            if(existItem.searchByName(name) == True):\n",
    "                                existItem.range = desc.split(' ')[i]\n",
    "                                isExist = True\n",
    "                        if isExist == False:\n",
    "                            item.range = desc.split(' ')[i]\n",
    "                            array.append(item)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "84b71a6b-2cf9-45c1-b355-2b4913dd933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage(url, element, typeStat):\n",
    "    # Init driver\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # Get item page\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for load page\n",
    "    time.sleep(2)\n",
    "\n",
    "    #Accept cookies\n",
    "    driver.find_element(By.XPATH,'/html/body/div[6]/div/div/div[2]/div[2]').click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    #Get all items\n",
    "    rows = driver.find_elements(By.XPATH, element)\n",
    "    getStats(rows, typeStat)\n",
    "    # Close driver\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0c1da1e5-5d63-4fb6-8758-824456800162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to get page and wait before getting another page to simulate a real behaviour\n",
    "getPage(\"https://bindingofisaacrebirth.fandom.com/wiki/Damage\", '//*[@id=\"mw-content-text\"]/div/table[4]/tbody/tr', \"damage\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d5476584-a832-4af6-b7d4-3bb6ce871712",
   "metadata": {},
   "outputs": [],
   "source": [
    "getPage(\"https://bindingofisaacrebirth.fandom.com/wiki/Tears\",  '//*[@id=\"mw-content-text\"]/div/table[5]/tbody/tr', \"tears\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "45b92bc2-5b1a-4aac-b623-f3a6c752a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "getPage(\"https://bindingofisaacrebirth.fandom.com/wiki/Range\",  '//*[@id=\"mw-content-text\"]/div/table[4]/tbody/tr', \"range\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4c9df4e8-92ce-47f1-86a6-63b99dafad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save items and characters into csv file\n",
    "def saveCsv(arraytmp, name):\n",
    "    array = []\n",
    "    for item in arraytmp:\n",
    "        array.append({\"name\": item.name, \"damage\": item.damage, \"tears\": item.tears, \"range\": item.range})\n",
    "    df = pd.DataFrame(array)\n",
    "    df.style\n",
    "    df.to_csv(name, index=False)  \n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b2eac490-f96f-43eb-a075-4e6fa042246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name damage tears  range\n",
      "0           Abaddon   +1.5             \n",
      "1         Capricorn   +0.5        +0.75\n",
      "2  Cat-O-Nine-Tails     +1             \n",
      "3       Dark Matter     +1             \n",
      "4     Death's Touch   +1.5             \n"
     ]
    }
   ],
   "source": [
    "saveCsv(array,'datas/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3546e-acfb-49df-8f18-09eb35b18bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary array for character\n",
    "tmpArrayCharacters = []\n",
    "\n",
    "def getPageCharacter():\n",
    "    # Init driver\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # Get character page\n",
    "    driver.get(\"https://bindingofisaacrebirth.fandom.com/fr/wiki/Personnages\")\n",
    "\n",
    "    # Wait for load page\n",
    "    time.sleep(2)\n",
    "\n",
    "    #Accept cookies\n",
    "    driver.find_element(By.XPATH,'/html/body/div[6]/div/div/div[2]/div[2]').click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    #Get all characters\n",
    "    names = driver.find_elements(By.XPATH, '//*[@id=\"mw-content-text\"]/div/div[3]/div/table/tbody/tr[2]/td')\n",
    "    damages = driver.find_elements(By.XPATH, '//*[@id=\"mw-content-text\"]/div/div[3]/div/table/tbody/tr[5]/td')\n",
    "    tears = driver.find_elements(By.XPATH, '//*[@id=\"mw-content-text\"]/div/div[3]/div/table/tbody/tr[6]/td')\n",
    "    ranges = driver.find_elements(By.XPATH, '//*[@id=\"mw-content-text\"]/div/div[3]/div/table/tbody/tr[8]/td')\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        if(i < len(names) - 1):\n",
    "            # New character instance for all\n",
    "            newCharacter = Character()\n",
    "            newCharacter.name = names[i + 1].text\n",
    "            newCharacter.damage = damages[i].text.split(' (')[0]\n",
    "            newCharacter.tears = tears[i].text\n",
    "            newCharacter.range = ranges[i].text\n",
    "            \n",
    "            tmpArrayCharacters.append(newCharacter)\n",
    "\n",
    "    # Close driver\n",
    "    driver.close()\n",
    "\n",
    "# Call function to get characters page\n",
    "getPageCharacter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a6661136-9829-454b-9da2-60046844b6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name damage tears  range\n",
      "0      Isaac    3.5    +0  23.75\n",
      "1  Magdalene    3.5    +0  23.75\n",
      "2       Cain    3.5    +0  17.75\n",
      "3      Judas    3.5    +0  23.75\n",
      "4        ???    3.5    +0  23.75\n"
     ]
    }
   ],
   "source": [
    "saveCsv(tmpArrayCharacters,'datas/characters.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da19158f-3763-4957-93dd-84affc39d602",
   "metadata": {},
   "source": [
    "--- Code in request.py ---\n",
    "\n",
    "### get character from characters.csv and get stats ####\n",
    "with open('datas/characters.csv', 'r') as csvfile:\n",
    "    characters = csv.reader(csvfile)\n",
    "    characters = list(characters)\n",
    "    damage = characters[int(sys.argv[1])][1]\n",
    "    tears = characters[int(sys.argv[1])][2]\n",
    "    statRange = characters[int(sys.argv[1])][3]\n",
    "    print(f\"--- {characters[int(sys.argv[1])][0]} ---\")\n",
    "    \n",
    "### get items from items.csv and get stats ####\n",
    "with open('datas/items.csv', 'r') as csvfile:\n",
    "    items = csv.reader(csvfile)\n",
    "    items = list(items)\n",
    "    ### loop in argv to get all items we want and add stats ###\n",
    "    for i in range(len(sys.argv)):\n",
    "        if i > 1:\n",
    "            damage = float(damage) + float(items[int(sys.argv[i])][1])\n",
    "            tears = float(tears) + float(items[int(sys.argv[i])][2])\n",
    "            statRange = float(statRange) + float(items[int(sys.argv[i])][3])\n",
    "    print(f\"Damage: {damage}\")\n",
    "    print(f\"Tears: {tears}\")\n",
    "    print(f\"Range: {statRange}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5ce0cd-8973-4fa4-a0dd-0c4b9e8c7107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Samson ---\n",
      "Damage: 7.0\n",
      "Tears: -0.05\n",
      "Range: 19.0\n"
     ]
    }
   ],
   "source": [
    "# first argument (7) -> character and others (1,5,9) -> items\n",
    "!python request.py 7 1 5 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674d124-6cb6-44eb-bea4-a101aafe6732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
